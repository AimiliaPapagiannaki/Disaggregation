{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import requests\n",
    "import numpy as np\n",
    "from pandas import ExcelWriter\n",
    "import os\n",
    "import glob\n",
    "import pytz\n",
    "from dateutil.tz import gettz\n",
    "import timeit\n",
    "from time import sleep\n",
    "\n",
    "# from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_rows', 50000)\n",
    "pd.set_option('display.max_columns', 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(devid, acc_token, address, start_time, end_time, descriptors):\n",
    "\n",
    "\n",
    "    r2 = requests.get(\n",
    "        url=address + \"/api/plugins/telemetry/DEVICE/\" + devid + \"/values/timeseries?keys=\" + descriptors + \"&startTs=\" + start_time + \"&endTs=\" + end_time + \"&agg=NONE&limit=1000000\",\n",
    "        headers={'Content-Type': 'application/json', 'Accept': '*/*', 'X-Authorization': acc_token}).json()\n",
    "    if r2:\n",
    "        print('request completed')\n",
    "        df = pd.DataFrame([])\n",
    "\n",
    "        for desc in r2.keys():\n",
    "            df1 = pd.DataFrame(r2[desc])\n",
    "            df1.set_index('ts', inplace=True)\n",
    "            df1.columns = [str(desc)]\n",
    "            df = pd.concat([df, df1], axis=1)\n",
    "\n",
    "        \n",
    "        if df.empty == False:\n",
    "\n",
    "            df.reset_index(drop=False, inplace=True)\n",
    "            df = df.sort_values(by=['ts'])\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            df.set_index('ts', inplace=True, drop=True)\n",
    "            for col in df.columns:\n",
    "                df[col] = df[col].astype('float')\n",
    "\n",
    "            df = df.groupby(df.index).max()\n",
    "            \n",
    "        else:\n",
    "            df = pd.DataFrame([])\n",
    "    else:\n",
    "        df = pd.DataFrame([])\n",
    "#         print('Empty json!')\n",
    "    return df\n",
    "\n",
    "def request_data(start_time,end_time,devid,acc_token,address,descriptors):\n",
    "    df = pd.DataFrame([])\n",
    "    svec = np.arange(int(start_time[0]),int(end_time[0]),3600000)\n",
    "    hour = 1\n",
    "    for st in svec:\n",
    "        print(hour)\n",
    "        hour = hour+1\n",
    "        en = st+3600000-1\n",
    "\n",
    "        if int(end_time[0])-en<=0: en = int(end_time[0])\n",
    "    #         print('start and end of iteration:',st,en)\n",
    "\n",
    "        tmp = read_data(devid, acc_token, address, str(st), str(en), descriptors)\n",
    "        if not tmp.empty:\n",
    "            df = pd.concat([df,tmp])\n",
    "        sleep(1)\n",
    "\n",
    "    df['ts'] = pd.to_datetime(df.index,utc=True, unit='ms')\n",
    "    df['ts'] = df['ts'].dt.tz_convert('Europe/Athens')\n",
    "\n",
    "    df.set_index('ts',inplace=True, drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def run_models(df,maphase,phase,mdlphase,mdlpath):\n",
    "#     step=20\n",
    "    events = []\n",
    "    nums = []\n",
    "    state = []\n",
    "    ev_ts = []\n",
    "    dpwr = [] # delta active power --> |previous power - current power|\n",
    "    conflicts = {}\n",
    "    ln=0\n",
    "    i=0\n",
    "    \n",
    "    for k in range(0,df.shape[0]):\n",
    "\n",
    "            df_pr = np.reshape(df.iloc[k].to_numpy(), (-1, 8))\n",
    "            mdlsum=0\n",
    "            assigned = False\n",
    "            print(df.index[k])\n",
    "            # run all models for this phase\n",
    "            for j in range(0,len(mdlphase[phase])):\n",
    "                filename = mdlpath+str(mdlphase[phase][j])+'.sav'\n",
    "                mdl = pickle.load(open(filename, 'rb'))\n",
    "                y_pred = mdl.predict(df_pr)\n",
    "                print(mdlphase[phase][j],y_pred)\n",
    "#                 print(y_pred)\n",
    "                if np.sum(y_pred)>=0.75*len(y_pred):\n",
    "#                 if np.sum(y_pred[1:])>=0.75*len(y_pred):\n",
    "                    \n",
    "                    if assigned==False: \n",
    "#                         dpwr.append(np.abs(np.mean(change['pwr'].iloc[-20:-10])-np.mean(steady['pwr'])))\n",
    "                        nums.append(np.sum(y_pred))\n",
    "                        mdlsum = np.sum(y_pred)\n",
    "#                         print(mdlphase[phase][j])\n",
    "                        events.append(mdlphase[phase][j])\n",
    "#                         print(mdlphase[phase][j], tsm)\n",
    "                        ev_ts.append(df.index[k])\n",
    "#                         state.append(st)\n",
    "                        assigned=True\n",
    "                        \n",
    "\n",
    "                        i=i+1\n",
    "                    else:\n",
    "                        if np.sum(y_pred)>mdlsum:#nums[i-1]:\n",
    "#                             print('previous sum %d, current sum %d:' % (mdlsum,np.sum(y_pred)))\n",
    "                            events[-1] = mdlphase[phase][j]\n",
    "#                             events.append(mdlphase[phase][j])\n",
    "                            mdlsum = np.sum(y_pred)\n",
    "                        elif np.sum(y_pred)==mdlsum:#nums[i-1]:\n",
    "                            conflicts[ev_ts[i-1]]= [mdlphase[phase][j]]\n",
    "                            print('New conflict at time %s, prev app is %s new app is %s' % (ev_ts[i-1],events[-1],mdlphase[phase][j]))\n",
    "            print('*******************************************')\n",
    "    #end of while\n",
    "    \n",
    "    ev = confl_postproc(events,state,ev_ts,conflicts,dpwr)\n",
    "    return ev\n",
    "\n",
    "\n",
    "def run_models2(df,maphase,phase,mdlphase,mdlpath):\n",
    "#     step=20\n",
    "    events = []\n",
    "    nums = []\n",
    "    state = []\n",
    "    ev_ts = []\n",
    "    dpwr = [] # delta active power --> |previous power - current power|\n",
    "    conflicts = {}\n",
    "    ln=0\n",
    "    i=0\n",
    "    mdlpath = '../../Desktop/windowsshare/stelios_data/aggmodels/'\n",
    "    for k in range(0,df.shape[0]):\n",
    "\n",
    "            df_pr = np.reshape(df.iloc[k].to_numpy(), (-1, 8))\n",
    "            mdlsum=0\n",
    "            assigned = False\n",
    "            print(df.index[k])\n",
    "            # run all models for this phase\n",
    "            filename = mdlpath+'mdl1.sav'\n",
    "            mdl = pickle.load(open(filename, 'rb'))\n",
    "            y_pred = mdl.predict(df_pr)\n",
    "            print(y_pred)\n",
    "#                 print(y_pred)\n",
    "#                 if np.sum(y_pred)>=0.75*len(y_pred):\n",
    "                \n",
    "    #end of while\n",
    "    \n",
    "    ev = confl_postproc(events,state,ev_ts,conflicts,dpwr)\n",
    "    return ev\n",
    "\n",
    "\n",
    "def events_clearing(ev,events,mappings):\n",
    "    # convert categorical variables to numeric\n",
    "\n",
    "    if not ev.empty:\n",
    "        ev.replace({'appl': { v : k for k, v in mappings.items() }},inplace=True)\n",
    "\n",
    "        ev = ev.resample('1S').max()\n",
    "        globals()['ev%s' % phase] = ev.copy()\n",
    "\n",
    "        # append events dataframes to dictionary\n",
    "        events.append(globals()['ev%s' % phase])\n",
    "    #     mappings.append(globals()['d%s' % phase])\n",
    "\n",
    "    return events    \n",
    "\n",
    "\n",
    "\n",
    "def confl_postproc(events,state,ev_ts,conflicts,dpwr):\n",
    "    \n",
    "    ev = pd.DataFrame([])\n",
    "    ev['appl'] = events\n",
    "#     ev['state'] = state\n",
    "    ev['ts'] = ev_ts\n",
    "#     ev['dpwr'] = dpwr\n",
    "    ev=ev.dropna()\n",
    "    ev.set_index('ts',inplace=True)\n",
    "\n",
    "    if len(conflicts)>0: # if there are conflicts\n",
    "        confl = pd.DataFrame(conflicts).T\n",
    "        confl.columns = ['conflict']\n",
    "        ev = pd.concat([ev,confl],axis=1)\n",
    "\n",
    "        \n",
    "        for i in range(5,ev.shape[0]-5):\n",
    "            if pd.isna(ev['conflict'].iloc[i])==False:\n",
    "        #         print(ev['conflict'].iloc[i],ev['appl'].iloc[i],ev['appl'].iloc[i-1])\n",
    "        \n",
    "                # check neighborhood -- 5 previous and 5 next points-- to decide if conflict will replace value\n",
    "                if ev['conflict'].iloc[i]==ev['appl'].iloc[i-5:i+5].value_counts()[:1].index.tolist()[0]:\n",
    "                    #print('appliance before conflict:',ev.iloc[i])\n",
    "                    ev['appl'].iloc[i] = ev['conflict'].iloc[i]\n",
    "                    ev['conflict'].iloc[i] = np.nan\n",
    "                    #print('appliance after conflict:',ev.iloc[i])\n",
    "                    \n",
    "    else:\n",
    "        ev['conflict'] = np.nan\n",
    "#         ev.drop('conflict',axis=1,inplace=True)\n",
    "\n",
    "    return ev\n",
    "\n",
    " \n",
    "# heatpump post process\n",
    "def hp_postproc(events,mappings):\n",
    "    phases = ['A','B','C']\n",
    "\n",
    "    if len(events)==3:\n",
    "        # encode conflicts column with corresponding dictionary values\n",
    "        for i in range(0,3):\n",
    "            if events[i]['conflict'].notnull().sum()>0:\n",
    "                events[i].replace({'conflict': { v : k for k, v in mappings[i].items() }},inplace=True)\n",
    "\n",
    "        # indexes of rows where heatpump was found at each phase\n",
    "        indA= events[0].loc[events[0]['appl'] == max(mappings[0], key=lambda k: mappings[0][k] == 'heatpumpA')].index\n",
    "        indB= events[1].loc[events[1]['appl'] == max(mappings[1], key=lambda k: mappings[1][k] == 'heatpumpB')].index\n",
    "        indC= events[2].loc[events[2]['appl'] == max(mappings[2], key=lambda k: mappings[2][k] == 'heatpumpC')].index\n",
    "\n",
    "        # if there is an intersection between at least two phases' indexes, assign appliance=heatpump on the ohter phase\n",
    "        events[0].loc[indB.intersection(indC),'appl']=max(mappings[0], key=lambda k: mappings[0][k] == 'heatpumpA')\n",
    "        events[1].loc[indA.intersection(indC),'appl']=max(mappings[1], key=lambda k: mappings[1][k] == 'heatpumpB')\n",
    "        events[2].loc[indA.intersection(indB),'appl']=max(mappings[2], key=lambda k: mappings[2][k] == 'heatpumpC')\n",
    "\n",
    "        # if heatpump is found at only one phase, this is a false positive. Replace with conflict or leave empty\n",
    "        events[0].loc[indA.difference(indB),'appl'] = events[0].loc[indA.difference(indB),'conflict']\n",
    "        events[1].loc[indB.difference(indC),'appl'] = events[1].loc[indB.difference(indC),'conflict']\n",
    "        events[2].loc[indC.difference(indA),'appl'] = events[2].loc[indC.difference(indA),'conflict']\n",
    "    \n",
    "    return events\n",
    "\n",
    "\n",
    "def postproc(events):\n",
    "    # drop events corresponding to only one appearance of an appliance \n",
    "    for i in range(0,len(events)):\n",
    "        singlapp = events[i]['appl'].value_counts()\n",
    "        if singlapp[singlapp==1].shape[0]>0:\n",
    "            events[i] = events[i][events[i]['appl'] != singlapp[singlapp==1].index.values[0]]\n",
    "            print('appliance with one appearance:',mappings[i][singlapp[singlapp==1].index.values[0]])\n",
    "    return events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set phase and appliances' mappings to dictionaries\n",
    "mdlpath = '../../Desktop/windowsshare/stelios_data/models30/'\n",
    "maphase = {'A':['avgPA1','stdPA1','minPA1','maxPA1','avgRA1','stdRA1','minRA1','maxRA1','avgPA2','stdPA2','minPA2','maxPA2','avgRA2','stdRA2','minRA2','maxRA2','avgPA3','stdPA3','minPA3','maxPA3','avgRA3','stdRA3','minRA3','maxRA3','avgPA4','stdPA4','minPA4','maxPA4','avgRA4','stdRA4','minRA4','maxRA4'],'B':['avgPB1','stdPB1','minPB1','maxPB1','avgRB1','stdRB1','minRB1','maxRB1','avgPB2','stdPB2','minPB2','maxPB2','avgRB2','stdRB2','minRB2','maxRB2','avgPB3','stdPB3','minPB3','maxPB3','avgRB3','stdRB3','minRB3','maxRB3','avgPB4','stdPB4','minPB4','maxPB4','avgRB4','stdRB4','minRB4','maxRB4'],'C':['avgPC1','stdPC1','minPC1','maxPC1','avgRC1','stdRC1','minRC1','maxRC1','avgPC2','stdPC2','minPC2','maxPC2','avgRC2','stdRC2','minRC2','maxRC2','avgPC3','stdPC3','minPC3','maxPC3','avgRC3','stdRC3','minRC3','maxRC3','avgPC4','stdPC4','minPC4','maxPC4','avgRC4','stdRC4','minRC4','maxRC4']}\n",
    "mdlphase = {'A':['fridge','heatpumpA','oven','stove','wash'],'B':['coffee','dish','freezer','heatpumpB'],'C':['iron','ironpress','heatpumpC','PC']}\n",
    "\n",
    "# devmap = {'mdl0':'dishwasher','mdl1':'entilator','mdl2':'freezer','mdl3':'fridge','mdl4':'heatpumpA','mdl5':'heatpumpB','mdl6':'heatpumpC','mdl7':'iron','mdl8':'ironpress','mdl9':'Oven','mdl10':'stove','mdl11':'vacuum','mdl12':'washingMashine'}\n",
    "\n",
    "# Download events for phase\n",
    "devid = '5163caf0-0d63-11eb-97dd-c792ed4b3104'\n",
    "\n",
    "\n",
    "# year = 2020\n",
    "# month = 9\n",
    "# day = 19\n",
    "\n",
    "tmzn = 'Europe/Athens'\n",
    "# st = datetime.datetime(year,month, day, tzinfo = gettz(tmzn))\n",
    "# daily_offset = 86400000\n",
    "# print('start:',st)\n",
    "\n",
    "# start_time = [1602842400000] #16/10\n",
    "# end_time = [1602860116000] #16/10\n",
    "\n",
    "\n",
    "start_time = [1596751200000] #16/10\n",
    "end_time = [1596762000000] #16/10\n",
    "\n",
    "address = \"http://52.77.235.183:8080\"\n",
    "\n",
    "r = requests.post(address + \"/api/auth/login\",\n",
    "                  json={'username': 'tenant@thingsboard.org', 'password': 'tenant'}).json()\n",
    "\n",
    "acc_token = 'Bearer' + ' ' + r['token']\n",
    "##########################\n",
    "# timediff = int(end_time[0])-int(start_time[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "request completed\n",
      "2\n",
      "request completed\n",
      "3\n",
      "request completed\n",
      "4\n",
      "request completed\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "phase='A'\n",
    "descriptors = ','.join(maphase[phase])\n",
    "df = request_data(start_time,end_time,devid,acc_token,address,descriptors)\n",
    "# df = df.dropna()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-21 01:31:10+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 01:47:18+03:00\n",
      "[1 1 2 2]\n",
      "2020-10-21 01:48:55+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:00:19+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:01:19+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:03:34+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:13:33+03:00\n",
      "[1 1 0 0]\n",
      "2020-10-21 02:23:13+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:33:26+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:33:31+03:00\n",
      "[2 2 2 2]\n",
      "2020-10-21 02:33:36+03:00\n",
      "[2 2 2 1]\n",
      "2020-10-21 02:33:46+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:34:56+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:40:29+03:00\n",
      "[2 2 2 2]\n",
      "2020-10-21 02:40:34+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:40:44+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:40:49+03:00\n",
      "[2 2 2 2]\n",
      "2020-10-21 02:40:54+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:42:04+03:00\n",
      "[1 1 1 0]\n",
      "2020-10-21 02:47:37+03:00\n",
      "[2 2 2 2]\n",
      "2020-10-21 02:47:42+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:47:47+03:00\n",
      "[2 2 2 2]\n",
      "2020-10-21 02:47:52+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:48:02+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:49:12+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:54:47+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:54:57+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:55:02+03:00\n",
      "[2 2 2 2]\n",
      "2020-10-21 02:55:07+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:56:17+03:00\n",
      "[1 1 1 1]\n",
      "2020-10-21 02:57:27+03:00\n",
      "[0 0 0 0]\n",
      "2020-10-21 03:03:17+03:00\n",
      "[1 0 1 1]\n",
      "2020-10-21 03:11:21+03:00\n",
      "[0 0 0 0]\n",
      "2020-10-21 03:11:36+03:00\n",
      "[2 2 2 2]\n",
      "2020-10-21 03:28:43+03:00\n",
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Run Multiclassification\n",
    "ev = run_models2(df,maphase,phase,mdlphase,mdlpath)\n",
    "# drA = [drn['entilator'],drn['fridge'],drn['heatpumpA'],drn['oven'],drn['stove'],drn['vacuum'],drn['wash']]\n",
    "# {1:fridge, 2:heatpumpA, 3:oven, 4:stove,5:vacuum, 6:wash}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-21 18:35:55+03:00\n",
      "fridge [1 1 1 1]\n",
      "heatpumpA [0 0 0 0]\n",
      "oven [0 0 0 0]\n",
      "stove [0 0 0 0]\n",
      "wash [0 0 0 0]\n",
      "*******************************************\n",
      "2020-10-21 19:04:49+03:00\n",
      "fridge [0 0 1 1]\n",
      "heatpumpA [0 0 0 0]\n",
      "oven [1 0 0 0]\n",
      "stove [0 0 0 0]\n",
      "wash [0 0 1 1]\n",
      "*******************************************\n",
      "2020-10-21 19:35:32+03:00\n",
      "fridge [1 1 1 1]\n",
      "heatpumpA [0 0 0 0]\n",
      "oven [0 0 0 0]\n",
      "stove [0 0 0 0]\n",
      "wash [0 0 0 0]\n",
      "*******************************************\n",
      "2020-10-21 20:06:56+03:00\n",
      "fridge [0 0 1 1]\n",
      "heatpumpA [0 0 0 0]\n",
      "oven [1 0 0 0]\n",
      "stove [0 0 0 0]\n",
      "wash [0 0 1 1]\n",
      "*******************************************\n",
      "2020-10-21 20:36:49+03:00\n",
      "fridge [1 1 1 1]\n",
      "heatpumpA [0 0 0 0]\n",
      "oven [0 0 0 0]\n",
      "stove [0 0 0 0]\n",
      "wash [0 0 0 0]\n",
      "*******************************************\n",
      "2020-10-21 21:13:01+03:00\n",
      "fridge [0 0 1 1]\n",
      "heatpumpA [0 0 0 0]\n",
      "oven [1 0 0 0]\n",
      "stove [0 0 0 0]\n",
      "wash [0 0 1 1]\n",
      "*******************************************\n",
      "2020-10-21 21:41:36+03:00\n",
      "fridge [1 1 1 1]\n",
      "heatpumpA [0 0 0 0]\n",
      "oven [0 0 0 0]\n",
      "stove [0 0 0 0]\n",
      "wash [0 0 0 0]\n",
      "*******************************************\n",
      "2020-10-21 21:49:34+03:00\n",
      "fridge [0 0 0 1]\n",
      "heatpumpA [0 0 0 0]\n",
      "oven [0 0 0 0]\n",
      "stove [0 0 0 0]\n",
      "wash [0 0 1 1]\n",
      "*******************************************\n",
      "2020-10-21 22:07:54+03:00\n",
      "fridge [1 1 1 1]\n",
      "heatpumpA [0 0 0 0]\n",
      "oven [0 0 0 0]\n",
      "stove [0 0 0 0]\n",
      "wash [1 1 1 1]\n",
      "New conflict at time 2020-10-21 22:07:54+03:00, prev app is fridge new app is wash\n",
      "*******************************************\n",
      "2020-10-21 22:25:44+03:00\n",
      "fridge [0 0 0 0]\n",
      "heatpumpA [0 0 0 0]\n",
      "oven [0 0 0 0]\n",
      "stove [0 0 0 0]\n",
      "wash [0 1 1 1]\n",
      "*******************************************\n"
     ]
    }
   ],
   "source": [
    "# i=0\n",
    "# mappings=[]\n",
    "# for key,value in mdlphase.items():\n",
    "#     # create list  of dictionaries for each phase's appliances with integer keys\n",
    "#     mappings.append(dict(zip(range(len(value)),value)))\n",
    "ev = run_models(df,maphase,phase,mdlphase,mdlpath)\n",
    "# events = events_clearing(ev,events,mappings[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "heatpumpB    12\n",
       "coffee        9\n",
       "freezer       6\n",
       "dish          3\n",
       "Name: appl, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev['appl'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ev.loc[ev['appl']=='heatpumpA','appl'] = ev.loc[ev['appl']=='heatpumpA','conflict']\n",
    "ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "events = []\n",
    "mappings=[]\n",
    "for key,value in mdlphase.items():\n",
    "    # create list  of dictionaries for each phase's appliances with integer keys\n",
    "    mappings.append(dict(zip(range(len(value)),value)))\n",
    "\n",
    "i=0\n",
    "for phase in ['A','B','C']:\n",
    "    print('phase ',phase)\n",
    "    descriptors = ','.join(maphase[phase])\n",
    "\n",
    "    df = request_data(start_time,end_time,devid,acc_token,address,descriptors)\n",
    "    \n",
    "    ev = run_models(df,maphase,phase,mdlphase,mdlpath)\n",
    "    \n",
    "    events = events_clearing(ev,events,mappings[i])\n",
    "    \n",
    "    i = i+1\n",
    "\n",
    "# ensure heatpump appears to function across all 3 phases, otherwise it's a false positive\n",
    "events = hp_postproc(events,mappings)\n",
    "# remove events of appliances that appear only once\n",
    "events = postproc(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(events)):\n",
    "    a = events[i]['appl'].unique()\n",
    "    a = a[a==a]\n",
    "    print(a)\n",
    "    for j in a:\n",
    "        events[i].loc[events[i]['appl']==j] = events[i].loc[events[i]['appl']==j][events[i].loc[events[i]['appl']==j]['state']!= events[i].loc[events[i]['appl']==j]['state'].shift()]\n",
    "        \n",
    "        tmp = events[i].loc[events[i]['appl']==j].copy()\n",
    "        \n",
    "#         # if 1st event is 0 then drop\n",
    "#         if tmp['state'].iloc[0]<1:\n",
    "#             tmp = tmp.iloc[1:]\n",
    "#         # if last event is 1 then drop\n",
    "#         if tmp['state'].iloc[-1]>0:\n",
    "#             tmp = tmp.iloc[:-1]\n",
    "        \n",
    "        # calculate time difference between on/off\n",
    "        tmp = tmp.loc[tmp['state']>=0]\n",
    "        tmp['ts'] =  tmp.index\n",
    "        tmp['dif'] = tmp['ts'].values-tmp['ts'].shift().values\n",
    "        tmp['dif'] = tmp['dif'].dt.seconds.fillna(0)\n",
    "        \n",
    "        # drop on/offs with duration less than 1 min\n",
    "#         tmp = tmp[(tmp['dif']>60) | (tmp['dif'].shift(-1)>60) | (tmp['dif']==0)]\n",
    "        \n",
    "        # keep only first instance of each state\n",
    "        tmp.loc[(tmp['state']==0.0) & (tmp['state'].shift()==1.0),'onoff'] = 1\n",
    "        tmp.loc[(tmp['state']==1.0) & (tmp['state'].shift()==0.0) & (tmp['onoff'].shift()==1),'onoff'] = 1\n",
    "        tmp['onoff'].iloc[0] = 1\n",
    "#         tmp = tmp.loc[(tmp['state']==0.0) & (tmp['state'].shift()==1.0)]\n",
    "        \n",
    "        #calculate time difference again\n",
    "        tmp['dif'] = tmp['ts'].values-tmp['ts'].shift().values\n",
    "        tmp['dif'] = tmp['dif'].dt.seconds.fillna(0)\n",
    "        tmp.drop('ts',axis=1, inplace=True)  \n",
    "        \n",
    "#         tmp = tmp.loc[tmp['onoff']==1]\n",
    "        \n",
    "        events[i] = events[i].loc[events[i]['appl']!=j]\n",
    "        events[i] = pd.concat([events[i],tmp[['appl','state','dpwr','conflict','dif','onoff']]])\n",
    "        events[i].sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "events[0][events[0]['appl']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[1].loc[events[1]['appl']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prA = pd.DataFrame(events[0])\n",
    "prA.to_csv('pwrA_140samples_10win.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download full house data\n",
    "devid = '4353f360-98d6-11ea-8d54-4d0d5d00237b'\n",
    "descriptors = 'pwrA,cnrgA,pwrB,cnrgB,pwrC,cnrgC'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "address = \"http://52.77.235.183:8080\"\n",
    "\n",
    "r = requests.post(address + \"/api/auth/login\",\n",
    "                  json={'username': 'tenant@thingsboard.org', 'password': 'tenant'}).json()\n",
    "\n",
    "# acc_token is the token to be used in the next request\n",
    "acc_token = 'Bearer' + ' ' + r['token']\n",
    "\n",
    "\n",
    "timediff = int(end_time[0])-int(start_time[0])\n",
    "\n",
    "# if difference between end and start time is greater than 15 minutes, split data \n",
    "\n",
    "summary = pd.DataFrame([])\n",
    "svec = np.arange(int(start_time[0]),int(end_time[0]),3000000)\n",
    "hour = 1\n",
    "for st in svec:\n",
    "    print(hour)\n",
    "    hour = hour+1\n",
    "    en = st+3000000-1\n",
    "\n",
    "    if int(end_time[0])-en<=0: en = int(end_time[0])\n",
    "#         print('start and end of iteration:',st,en)\n",
    "\n",
    "    tmp = read_data(devid, acc_token, address, str(st), str(en), descriptors)\n",
    "    if not tmp.empty:\n",
    "        summary = pd.concat([summary,tmp])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary = summary[['pwrA','cnrgA']]\n",
    "summary['ts'] = pd.to_datetime(summary.index,utc=True, unit='ms')\n",
    "summary['ts'] = summary['ts'].dt.tz_convert('Europe/Athens')\n",
    "\n",
    "summary.set_index('ts',inplace=True, drop=True)\n",
    "# summary = summary.resample('1S').mean()\n",
    "\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load average power of each appliance\n",
    "avgpr = pd.read_csv('avg_pwr.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = summary.copy()\n",
    "ndf = ndf.resample('1S').mean()\n",
    "ndf = ndf[['cnrgA','pwrA']]\n",
    "ndf = pd.concat([ndf,events[0]],axis=1)\n",
    "\n",
    "ndf['pr_pwr'] = (ndf['pwrA'].shift(3)+ndf['pwrA'].shift(4)+ndf['pwrA'].shift(5)+ndf['pwrA'].shift(6))/4\n",
    "\n",
    "tmp = ndf.loc[ndf['appl']==1]\n",
    "tmp['dpwr'] = tmp['pr_pwr']-tmp['pwrA']\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fridge\n",
    "ndf = summary.copy()\n",
    "ndf = ndf.resample('1S').mean()\n",
    "ndf = ndf[['cnrgA','pwrA']]\n",
    "ndf = pd.concat([ndf,events[0]],axis=1)\n",
    "\n",
    "ndf['pr_pwr'] = (ndf['pwrA'].shift(3)+ndf['pwrA'].shift(4)+ndf['pwrA'].shift(5)+ndf['pwrA'].shift(6))/4\n",
    "\n",
    "tmp = ndf.loc[ndf['appl']==1]\n",
    "\n",
    "# tmp = tmp.iloc[:-1]\n",
    "\n",
    "# check if fridge is already ON when day begins\n",
    "if tmp['state'].iloc[0]==0.0:\n",
    "    tmp['dif'].iloc[0] = (tmp.index[0].hour*3600)+(tmp.index[0].minute*60)+tmp.index[0].second\n",
    "\n",
    "    # check if fridge is left at ON state as the day ends\n",
    "if tmp['state'].iloc[-1]==1.0:\n",
    "    tmp['dif'].iloc[-1] = (23-tmp.index[-1].hour)*3600+(60-tmp.index[0].minute)*60+(60-tmp.index[0].second)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "tmp = tmp[tmp['state']==0]\n",
    "tmp['dE'] = (tmp['dif']*avgpr.loc[avgpr['app']=='fridge','pwr'].values[0])/3600\n",
    "tmp['dpwr'] = tmp['pr_pwr']-tmp['pwrA']\n",
    "\n",
    "# tmp['dE'] = (tmp['pr_pwr']-tmp['pwrA'])*tmp['dif']/3600\n",
    "\n",
    "\n",
    "tmp['dE'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dishwasher\n",
    "\n",
    "ndf = summary.copy()\n",
    "ndf = ndf.resample('1S').mean()\n",
    "ndf = ndf[['cnrgB','pwrB']]\n",
    "ndf = pd.concat([ndf,events[1]],axis=1)\n",
    "\n",
    "ndf['pr_pwr'] = (ndf['pwrB'].shift(3)+ndf['pwrB'].shift(4)+ndf['pwrB'].shift(5)+ndf['pwrB'].shift(6))/4\n",
    "\n",
    "tmp = ndf.loc[ndf['appl']==1]\n",
    "\n",
    " \n",
    "# tmp = tmp[tmp['state']==0]\n",
    "# # tmp['dE'] = (tmp['dif']*avgpr.loc[avgpr['app']=='dish','pwr'].values[0])/3600\n",
    "# tmp['dpwr'] = tmp['pr_pwr']-tmp['pwrB']\n",
    "\n",
    "# tmp['dE'] = (tmp['pr_pwr']-tmp['pwrB'])*tmp['dif']/3600\n",
    "# print('dE estimation is: ',tmp['dE'].sum())\n",
    "\n",
    "\n",
    "totaldif = (tmp.index.to_series()[-1]-tmp.index.to_series()[0]).total_seconds()\n",
    "dE = (tmp['cnrgB'].iloc[-1] - tmp['cnrgB'].iloc[0]) - (totaldif*tmp['pr_pwr'].iloc[0])/3600\n",
    "# gd = 1287\n",
    "# print('dE accuracy is:',(1-np.abs(gd-dE)/gd)*100)\n",
    "dE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = ['A','B','C']\n",
    "for j in range(0,1):\n",
    "    ndf = summary.copy()\n",
    "    ndf = ndf.resample('1S').mean()\n",
    "    ndf = pd.concat([ndf,events[j]],axis=1)\n",
    "\n",
    "    pwr = maphase[phases[j]][0]\n",
    "    fig = plt.figure(figsize=[15,7])\n",
    "    plt.plot(ndf.index,ndf[pwr],'c',alpha=0.7)#,df2.index,df2['rpwrB'])\n",
    "    colors = ['blueviolet','green','red','orchid','orange','aqua','deepskyblue']\n",
    "\n",
    "    values=[]\n",
    "    items = mappings[j].items() \n",
    "    for item in items: \n",
    "        values.append(item[1]) \n",
    "\n",
    "\n",
    "    for i in range(0,1):\n",
    "        cl = ndf['appl']==1\n",
    "        plt.scatter(ndf.index[cl], ndf[pwr][cl], color=colors[i],zorder=10)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Active power in Watts')\n",
    "    plt.legend(['totalPower']+['fridge'])\n",
    "    plt.title('Washing machine detected within aggregated power')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = ['A','B','C']\n",
    "for j in range(0,3):\n",
    "    ndf = summary.copy()\n",
    "    ndf = ndf.resample('1S').mean()\n",
    "    ndf = pd.concat([ndf,events[j]],axis=1)\n",
    "\n",
    "    pwr = maphase[phases[j]][0]\n",
    "    fig = plt.figure(figsize=[15,7])\n",
    "    plt.plot(ndf.index,ndf[pwr],'c',alpha=0.7)#,df2.index,df2['rpwrB'])\n",
    "    colors = ['aqua','green','deepskyblue','orchid','blueviolet','orange','red']\n",
    "\n",
    "    values=[]\n",
    "    items = mappings[j].items() \n",
    "    for item in items: \n",
    "        values.append(item[1]) \n",
    "\n",
    "\n",
    "    for i in range(0,len(mappings[j])):\n",
    "        cl = ndf['appl']==i\n",
    "        plt.scatter(ndf.index[cl], ndf[pwr][cl], color=colors[i],zorder=10)\n",
    "\n",
    "    plt.legend(['totalPower']+values)\n",
    "    plt.title('Appliances detected in phase '+phases[j]+' within a whole day')\n",
    "    plt.ylabel('Active power in Watts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
