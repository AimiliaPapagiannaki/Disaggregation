{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import requests\n",
    "import os\n",
    "import scipy.signal\n",
    "import scipy.stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import time\n",
    "from dateutil.tz import gettz\n",
    "from datetime import timedelta\n",
    "import calendar\n",
    "import datetime\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_nrg(start_date, end_date, devid):\n",
    "    \n",
    "    address = \"https://m3.meazon.com/\"\n",
    "\n",
    "    r = requests.post(address + \"api/auth/login\",\n",
    "                      json={'username': 'meazon@thingsboard.org', 'password': 'meazon'}).json()\n",
    "\n",
    "    # acc_token is the token to be used in the next request\n",
    "    acc_token = 'Bearer' + ' ' + r['token']\n",
    "    \n",
    "    # request all descriptors that have ever been assigned to this device\n",
    "    r1 = requests.get(url = address+\"api/plugins/telemetry/DEVICE/\"+devid+\"/keys/timeseries\",headers={'Content-Type': 'application/json', 'Accept': '*/*', 'X-Authorization': acc_token}).json()\n",
    " \n",
    "    \n",
    "#     descriptors = [x for x in r1]\n",
    "#     descriptors = ','.join(descriptors)\n",
    "    descriptors = 'pwrA,pwrB,pwrC'\n",
    "\n",
    "    start_time = str(start_date)\n",
    "    end_time = str(end_date)\n",
    "\n",
    "    # address =  \"https://m3.meazon.com/\"\n",
    "    r2 = requests.get(\n",
    "        url=address + \"api/plugins/telemetry/DEVICE/\" + devid + \"/values/timeseries?keys=\"+descriptors+\"&startTs=\" + start_time + \"&endTs=\" + end_time + \"&agg=NONE&limit=1000000\",\n",
    "        headers={'Content-Type': 'application/json', 'Accept': '*/*', 'X-Authorization': acc_token}).json()\n",
    "\n",
    "    # download temperature\n",
    "\n",
    "\n",
    "    if (r2):\n",
    "\n",
    "        df = pd.DataFrame([])\n",
    "        \n",
    "\n",
    "        \n",
    "        # read all descriptors at once\n",
    "        for desc in r2.keys():\n",
    "            df1 = pd.DataFrame(r2[desc])\n",
    "            df1.set_index('ts', inplace=True)\n",
    "            df1.columns = [str(desc)]\n",
    "            df = pd.concat([df,df1], axis = 1)\n",
    "        print(df.head())  \n",
    "        \n",
    "\n",
    "        df.reset_index(drop=False, inplace=True)\n",
    "        df['Timestamp'] = pd.to_datetime(df['ts'], unit='ms')\n",
    "        #         df['ts'] = df['ts'].dt.tz_localize('utc').dt.tz_convert('Europe/Athens').dt.tz_localize(None)\n",
    "        \n",
    "        df = df.sort_values(by=['Timestamp'])\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    else:\n",
    "        df = pd.DataFrame([])\n",
    "        print('Empty json!')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def fill_missing_values(df, interv):\n",
    "    # merge rows with same datetime to exclude nans\n",
    "    df = df.groupby(df.index).max()\n",
    "    df.sort_index(inplace=True)\n",
    "    # create datetime series to import missing dates and reindex\n",
    "    start_date = df.index[0]\n",
    "    end_date = df.index[-1]\n",
    "    idx = pd.date_range(start_date, end_date, freq=str(interv) + 'T')\n",
    "    df = df.reindex(idx)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_nrg_table(df):\n",
    "    df['cnrgA'] = df['cnrgA'].astype(float)\n",
    "    df['cnrgB'] = df['cnrgB'].astype(float)\n",
    "    df['cnrgC'] = df['cnrgC'].astype(float)\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y/%m/%d %H:%M:%S.%f')\n",
    "    df = df.sort_values(by=\"Timestamp\")\n",
    "\n",
    "    df['Timestamp'] = df['Timestamp'].astype('datetime64[s]')\n",
    "    df = df.set_index('Timestamp', drop=True)\n",
    "    df.index = df.index.map(lambda x: x.replace(second=0))\n",
    "\n",
    "    ####################\n",
    "    tmpdf = pd.DataFrame(df['cnrgA'].dropna())\n",
    "    tmpdf['minutes'] = tmpdf.index.minute\n",
    "    tmpdf['interv'] = tmpdf['minutes'].shift(-1) - tmpdf['minutes']\n",
    "    interv = int(tmpdf['interv'].value_counts().idxmax())\n",
    "    del tmpdf\n",
    "\n",
    "    df.index = df.index.round(str(interv) + 'T')\n",
    "\n",
    "    df = fill_missing_values(df, interv)\n",
    "    df['Timestamp'] = df.index\n",
    "    df['total'] = df['cnrgA'] + df['cnrgB'] + df['cnrgC']\n",
    "\n",
    "    return [df, interv]\n",
    "\n",
    "\n",
    "def conv_to_consumption(df):\n",
    "    #     convert cumulative energy to consumed energy\n",
    "\n",
    "    df['diffA'] = np.nan\n",
    "    df['diffB'] = np.nan\n",
    "    df['diffC'] = np.nan\n",
    "    df.loc[((df.cnrgA.isna() == False) & (df.cnrgA.shift().isna() == False)), 'diffA'] = df.cnrgA - df.cnrgA.shift()\n",
    "    df.loc[(df.cnrgB.isna() == False) & (df.cnrgB.shift().isna() == False), 'diffB'] = df.cnrgB - df.cnrgB.shift()\n",
    "    df.loc[(df.cnrgC.isna() == False) & (df.cnrgC.shift().isna() == False), 'diffC'] = df.cnrgC - df.cnrgC.shift()\n",
    "\n",
    "    df.diffA.iloc[0] = 0\n",
    "    df.diffB.iloc[0] = 0\n",
    "    df.diffC.iloc[0] = 0\n",
    "\n",
    "    df['total'] = np.nan\n",
    "    df.loc[(df.diffA.isna() == False) & (df.diffB.isna() == False) & (\n",
    "            df.diffC.isna() == False), 'total'] = df.diffA + df.diffB + df.diffC\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def find_nans(cnrg, energy, interv):\n",
    "    # store starting points of NaNs\n",
    "\n",
    "    df_start = energy[((energy[cnrg].isnull()) & (energy[cnrg].shift().isnull() == False))]\n",
    "    if df_start.empty == False:\n",
    "\n",
    "        if (np.isnan(energy[cnrg].iloc[0]) == True):\n",
    "\n",
    "            df2 = pd.DataFrame([])\n",
    "            df2['endpoint'] = energy.index[(energy[cnrg].isnull()) & (energy[cnrg].shift(-1).isnull() == False)].copy()\n",
    "            df2 = df2.iloc[1:]\n",
    "\n",
    "            df_start['endpoint'] = df2['endpoint']\n",
    "        else:\n",
    "            df_start['endpoint'] = energy.index[(energy[cnrg].isnull()) & (energy[cnrg].shift(-1).isnull() == False)]\n",
    "        df_start = df_start.drop(['cnrgA', 'cnrgB', 'cnrgC', 'total'], axis=1)\n",
    "\n",
    "        df_start['previous_dt'] = df_start.index - timedelta(minutes=interv)\n",
    "        df_start['next_dt'] = df_start.endpoint + timedelta(minutes=interv)\n",
    "        df_start['previous_week_start'] = df_start.previous_dt - timedelta(days=7)\n",
    "        df_start['previous_week_end'] = df_start.next_dt - timedelta(days=7)\n",
    "\n",
    "        df_start['next_week_start'] = df_start.previous_dt + timedelta(days=7)\n",
    "        df_start['next_week_end'] = df_start.next_dt + timedelta(days=7)\n",
    "\n",
    "    return df_start\n",
    "\n",
    "\n",
    "def backfill(row, cnrg, energy, interv):\n",
    "    tmp = pd.DataFrame(energy.loc[row.previous_week_start:row.previous_week_end])\n",
    "    if tmp.shape[0] == 0:\n",
    "        tmp = pd.DataFrame(\n",
    "            energy.loc[row.previous_week_start + timedelta(days=7):row.previous_week_end + timedelta(days=7)])\n",
    "    if tmp.shape[0] > 0:\n",
    "\n",
    "        start1 = tmp[cnrg].iloc[0]  # starting point of previous week\n",
    "        start2 = energy[cnrg].loc[row.previous_dt]  # starting point of current week\n",
    "\n",
    "        diff1 = tmp[cnrg].iloc[-1] - start1  # diff of previous week\n",
    "        diff2 = energy[cnrg].loc[row.next_dt] - start2  # diff of current week\n",
    "\n",
    "        for i in range(1, tmp.shape[0] - 1):\n",
    "            if ((tmp[cnrg].iloc[i] - start1) != diff1 and (diff1 != 0)):\n",
    "                perc = (tmp[cnrg].iloc[i] - start1) / diff1\n",
    "                energy[cnrg].loc[row.previous_dt + timedelta(minutes=i * interv)] = perc * diff2 + start2\n",
    "\n",
    "            else:\n",
    "                perc = 0\n",
    "                energy[cnrg].loc[row.previous_dt + timedelta(minutes=i * interv)] = energy[cnrg].loc[\n",
    "                    row.previous_dt + timedelta(minutes=i * interv - interv)]\n",
    "\n",
    "\n",
    "def forwardfill(row, cnrg, energy, interv):\n",
    "    tmp = energy.loc[row.next_week_start:row.next_week_end]\n",
    "    if tmp.shape[0] > 0:\n",
    "        k = 1\n",
    "        # while all intermediate values are nan\n",
    "        while ((tmp[cnrg].iloc[0] + tmp[cnrg].iloc[-1] == tmp[cnrg].sum()) & (\n",
    "                row.next_week_start - timedelta(days=k) >= energy.Timestamp.iloc[\n",
    "            0])):\n",
    "            tmp = energy.loc[row.next_week_start - timedelta(days=k):row.next_week_end - timedelta(days=k)]\n",
    "            k = k + 1\n",
    "\n",
    "        if tmp.shape[0] > 0:\n",
    "            start1 = tmp[cnrg].iloc[0]  # starting point of next week\n",
    "            diff1 = tmp[cnrg].iloc[-1] - start1  # diff of next week\n",
    "\n",
    "            start2 = energy[cnrg].loc[row.previous_dt]  # starting point of current week\n",
    "            diff2 = energy[cnrg].loc[row.next_dt] - start2  # diff of current week\n",
    "\n",
    "            for i in range(1, tmp.shape[0] - 1):\n",
    "\n",
    "                # if ((tmp[cnrg].iloc[i] - start1) != diff1 and (diff1 != 0) and (np.isnan(start1)==False)):\n",
    "                if ((tmp[cnrg].iloc[i] - start1) != diff1 and (diff1 != 0)):\n",
    "\n",
    "                    perc = (tmp[cnrg].iloc[i] - start1) / diff1\n",
    "                    energy[cnrg].loc[row.previous_dt + timedelta(minutes=i * interv)] = perc * diff2 + start2\n",
    "\n",
    "                else:\n",
    "                    perc = 0\n",
    "                    energy[cnrg].loc[row.previous_dt + timedelta(minutes=i * interv)] = energy[cnrg].loc[\n",
    "                        row.previous_dt + timedelta(minutes=i * interv - interv)]\n",
    "\n",
    "        else:\n",
    "            energy[cnrg] = energy[cnrg].interpolate(method='linear')\n",
    "\n",
    "\n",
    "    else:\n",
    "        k = 1\n",
    "        while ((tmp.shape[0] == 0) & ((row.next_dt + timedelta(hours=24 * k)) <= energy.Timestamp.iloc[-1])):\n",
    "            tmp = energy.loc[row.previous_dt + timedelta(hours=24 * k):row.next_dt + timedelta(hours=24 * k)]\n",
    "\n",
    "            k = k + 1\n",
    "\n",
    "        if tmp.shape[0] > 0:\n",
    "            start1 = tmp[cnrg].iloc[0]  # starting point of next week\n",
    "            diff1 = tmp[cnrg].iloc[-1] - start1  # diff of next week\n",
    "\n",
    "            start2 = energy[cnrg].loc[row.previous_dt]  # starting point of current week\n",
    "            diff2 = energy[cnrg].loc[row.next_dt] - start2  # diff of current week\n",
    "\n",
    "            for i in range(1, tmp.shape[0] - 1):\n",
    "\n",
    "                # if ((tmp[cnrg].iloc[i] - start1) != diff1 and (diff1 != 0) and (np.isnan(start1)==False)):\n",
    "                if ((tmp[cnrg].iloc[i] - start1) != diff1 and (diff1 != 0)):\n",
    "                    perc = (tmp[cnrg].iloc[i] - start1) / diff1\n",
    "                    energy[cnrg].loc[row.previous_dt + timedelta(minutes=i * interv)] = perc * diff2 + start2\n",
    "                else:\n",
    "                    perc = 0\n",
    "                    energy[cnrg].loc[row.previous_dt + timedelta(minutes=i * interv)] = energy[cnrg].loc[\n",
    "                        row.previous_dt + timedelta(minutes=i * interv - interv)]\n",
    "        else:\n",
    "            energy[cnrg] = energy[cnrg].interpolate(method='linear')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fill_nans(nrg, energy, interv):\n",
    "    for cnrg in nrg:\n",
    "\n",
    "        df_start = find_nans(cnrg, energy, interv)\n",
    "        prev_status = df_start.shape[0]\n",
    "        df_start.apply((lambda x: backfill(x, cnrg, energy, interv)), axis=1)\n",
    "        print('backfill ended')\n",
    "\n",
    "        while energy[cnrg].isna().sum() > 0:\n",
    "            \n",
    "            if ((energy[cnrg].isna().sum() == 1) & np.isnan(energy[cnrg].iloc[0])):\n",
    "                energy[cnrg].iloc[0] = energy[cnrg].iloc[1]\n",
    "\n",
    "            else:\n",
    "                df_start = find_nans(cnrg, energy, interv)\n",
    "                cur_status = df_start.shape[0]\n",
    "                if ((df_start.empty == False) and (cur_status < prev_status)):\n",
    "                    df_start.apply((lambda x: forwardfill(x, cnrg, energy, interv)), axis=1)\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    energy[cnrg] = energy[cnrg].interpolate(method='linear',limit_direction ='both')\n",
    "                    \n",
    "                prev_status = cur_status\n",
    "        print('forward fill ended')\n",
    "\n",
    "\n",
    "def fill_dropped_nrg(df, nrg, interv):\n",
    "    for cnrg in nrg:\n",
    "        dfnew = df[np.isfinite(df[cnrg])].copy()\n",
    "        dropped = dfnew[dfnew[cnrg] < dfnew[cnrg].shift()]\n",
    "\n",
    "        if dropped.empty == False:\n",
    "            # keep endpoint of range of reseted values\n",
    "            dropped['endpoint1'] = dfnew.index[dfnew[cnrg] > dfnew[cnrg].shift(-1)]\n",
    "\n",
    "            # shift endpoints to match starting points and set last endpoint as the last instance of df\n",
    "            dropped['endpoint'] = dropped['endpoint1'].shift(-1)\n",
    "            dropped['endpoint'].iloc[-1] = df.index[-1]\n",
    "\n",
    "            dropped.apply((lambda x: correct_dropped(x, cnrg, df, interv)), axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def correct_dropped(row, cnrg, df, interv):\n",
    "    # df[cnrg].loc[row.Timestamp:row.endpoint] = np.sum([df[cnrg], df[cnrg].loc[row.endpoint1]])\n",
    "    if df[cnrg].loc[row.Timestamp] > df[cnrg].loc[row.endpoint1 - timedelta(minutes=interv)]:\n",
    "        df[cnrg].loc[row.endpoint1] = df[cnrg].loc[row.Timestamp]\n",
    "    else:\n",
    "        df[cnrg].loc[row.Timestamp:row.endpoint] = np.sum(\n",
    "            [df[cnrg], np.abs(df[cnrg].loc[row.endpoint1] - df[cnrg].loc[row.Timestamp])])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_energy_data(start_date, end_date, devid):\n",
    "    print('Downloading cumulative energy...')\n",
    "    dfcnrg = download_nrg(start_date, end_date, devid)\n",
    "    if dfcnrg.empty == True:\n",
    "        energy = pd.DataFrame([])\n",
    "        interv = np.nan\n",
    "        return energy\n",
    "    else:\n",
    "        return dfcnrg\n",
    "#         nrg = ['cnrgA', 'cnrgB', 'cnrgC']\n",
    "#         [energy, interv] = create_nrg_table(dfcnrg)\n",
    "\n",
    "#         if ((energy.cnrgA.isna().sum() > 0.4 * energy.shape[0]) | (energy.shape[0] < 7 * 24 * (60 / interv))):\n",
    "#             print('Very few values!')\n",
    "#             energy = pd.DataFrame([])\n",
    "#             interv = np.nan\n",
    "#             return energy\n",
    "#         else:\n",
    "\n",
    "#             print('Correcting energy dropdowns')\n",
    "#             energy = fill_dropped_nrg(energy, nrg, interv)\n",
    "\n",
    "#             print('Filling missing values')\n",
    "#             energy = conv_to_consumption(energy)\n",
    "#             thresA = energy.diffA.mean() + 3 * energy.diffA.std()\n",
    "#             thresB = energy.diffB.mean() + 3 * energy.diffB.std()\n",
    "#             thresC = energy.diffC.mean() + 3 * energy.diffC.std()\n",
    "\n",
    "#             energy.loc[(energy.diffA.shift(-1) > thresA) & (energy.cnrgA.shift(-2) == np.nan), 'cnrgA'] = np.nan\n",
    "#             energy.loc[(energy.diffB.shift(-1) > thresB) & (energy.cnrgB.shift(-2) == np.nan), 'cnrgB'] = np.nan\n",
    "#             energy.loc[(energy.diffC.shift(-1) > thresC) & (energy.cnrgC.shift(-2) == np.nan), 'cnrgC'] = np.nan\n",
    "\n",
    "#             energy = conv_to_consumption(energy)\n",
    "#             fill_nans(nrg, energy, interv)\n",
    "#             energy = conv_to_consumption(energy)\n",
    "            \n",
    "    \n",
    "#             energy.sort_values(by=['Timestamp'], inplace=True)\n",
    "#             #             energy.nrgA = energy.nrgA / 1000\n",
    "#             #             energy.nrgB = energy.nrgB / 1000\n",
    "#             #             energy.nrgC = energy.nrgC / 1000\n",
    "#             energy.set_index(pd.to_datetime(energy.Timestamp, unit='ms'), inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#             print('Energy df has successfully been created')\n",
    "#             return energy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(X_train,y_train, X_test, y_test):\n",
    "    \n",
    "    \n",
    "    def objective(parameters, n_folds = 10):\n",
    "        \n",
    "        # fit model to the first half set\n",
    "        Dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        mdl = xgb.train(parameters, Dtrain)\n",
    "        \n",
    "        \n",
    "        Observed = np.array([])\n",
    "        Forecasted = np.array([])\n",
    "        \n",
    "\n",
    "        test_set = xgb.DMatrix(X_test, label=y_test)\n",
    "        y_pred = mdl.predict(test_set)\n",
    "\n",
    "            \n",
    "        loss = 100 - appliance_acc(y_test,y_pred)\n",
    "        \n",
    "        print('loss:',loss)\n",
    "        return {'loss': loss, 'parameters': parameters, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "    # Define the space to search for best hyperparameters\n",
    "    space = {\n",
    "        'n_estimators': hp.quniform('n_estimators', 100, 1000, 2),\n",
    "        'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "        'max_depth':  hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n",
    "        'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n",
    "        'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "        'gamma': hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "        'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "        'objective': 'reg:linear',\n",
    "        'eval_metric':'mae',\n",
    "        'booster': 'gbtree',\n",
    "        'tree_method': 'exact',\n",
    "        'silent': 1,\n",
    "        'seed':315469\n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "    trials = Trials()\n",
    "    \n",
    "    best = fmin(fn = objective, space = space,algo = tpe.suggest,trials = trials,max_evals = 30,verbose=0)\n",
    "    best_trial = sorted(trials.results, key = lambda x: x['loss'])\n",
    "    params = best_trial[0]['parameters']\n",
    "#     train_set = xgb.DMatrix(trainset[final_set], label = trainset['Consumption'])\n",
    "#     best_bayes_model = xgb.train(params,train_set)\n",
    "    xgb_acc = 100-best_trial[0]['loss']\n",
    "\n",
    "    \n",
    "\n",
    "#     print('Best acc:',xgb_acc)\n",
    "#     mdl = best_bayes_model\n",
    "        \n",
    "    \n",
    "    return (xgb_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading cumulative energy...\n",
      "                        pwrA           pwrB           pwrC\n",
      "ts                                                        \n",
      "1585324369772  1154.98510742  3.44256687164            NaN\n",
      "1585324369773            NaN            NaN  3.49745583534\n",
      "1585324429800  1153.28637695  3.44549489021  3.45500946045\n",
      "1585324489766  1151.36450195  3.41988015175  3.46013116837\n",
      "1585324550028  1149.54541016  3.49965167046  3.46891331673\n"
     ]
    }
   ],
   "source": [
    "devid = '306920b0-3a42-11ea-8762-6bf954fc5af1'\n",
    "\n",
    "\n",
    "end_ = (datetime.datetime.now())\n",
    "       \n",
    "start_ = end_ + relativedelta(months=-1)\n",
    "\n",
    "end_time = int(end_.timestamp()) * 1000\n",
    "start_time = int(start_.timestamp()) * 1000\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# make request\n",
    "indata = get_energy_data(start_time, end_time, devid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>pwrA</th>\n",
       "      <th>pwrB</th>\n",
       "      <th>pwrC</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1585324369772</td>\n",
       "      <td>1154.98510742</td>\n",
       "      <td>3.44256687164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-27 15:52:49.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1585324369773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.49745583534</td>\n",
       "      <td>2020-03-27 15:52:49.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1585324429800</td>\n",
       "      <td>1153.28637695</td>\n",
       "      <td>3.44549489021</td>\n",
       "      <td>3.45500946045</td>\n",
       "      <td>2020-03-27 15:53:49.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1585324489766</td>\n",
       "      <td>1151.36450195</td>\n",
       "      <td>3.41988015175</td>\n",
       "      <td>3.46013116837</td>\n",
       "      <td>2020-03-27 15:54:49.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1585324550028</td>\n",
       "      <td>1149.54541016</td>\n",
       "      <td>3.49965167046</td>\n",
       "      <td>3.46891331673</td>\n",
       "      <td>2020-03-27 15:55:50.028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ts           pwrA           pwrB           pwrC  \\\n",
       "0  1585324369772  1154.98510742  3.44256687164            NaN   \n",
       "1  1585324369773            NaN            NaN  3.49745583534   \n",
       "2  1585324429800  1153.28637695  3.44549489021  3.45500946045   \n",
       "3  1585324489766  1151.36450195  3.41988015175  3.46013116837   \n",
       "4  1585324550028  1149.54541016  3.49965167046  3.46891331673   \n",
       "\n",
       "                Timestamp  \n",
       "0 2020-03-27 15:52:49.772  \n",
       "1 2020-03-27 15:52:49.773  \n",
       "2 2020-03-27 15:53:49.800  \n",
       "3 2020-03-27 15:54:49.766  \n",
       "4 2020-03-27 15:55:50.028  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window(a, w , o , copy = False):\n",
    "    sh = (a.size - w + 1, w)\n",
    "    st = a.strides * 2\n",
    "    view = np.lib.stride_tricks.as_strided(a, strides = st, shape = sh)[0::o]\n",
    "    if copy:\n",
    "        return view.copy()\n",
    "    else:\n",
    "        return view\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def appliance_acc(y_true,y_pred):\n",
    "    acc = 1-(np.sum(np.abs(y_true-y_pred))/(2*np.sum(np.abs(y_true))))\n",
    "    acc = acc*100\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = [17,10])\n",
    "plt.grid(True)\n",
    "plt.plot(sm.pwrtotal)\n",
    "# plt.plot(plug1.pwr)\n",
    "# plt.plot(plug2.pwr)\n",
    "# plt.plot(plug4.pwr)\n",
    "# plt.plot(plug5.pwr)\n",
    "plt.plot(plg.pwr)\n",
    "# plt.plot(plug7.pwr)\n",
    "plt.legend(['Total','Freezer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert dfs to numpy arrays \n",
    "met_cur = sm['cur']\n",
    "met_cur = met_cur.to_numpy()\n",
    "sm = sm['pwrtotal']\n",
    "sm = sm.to_numpy()\n",
    "\n",
    "\n",
    "# Pass signal through median filter with 5 samples\n",
    "sm = sp.signal.medfilt(sm,5)\n",
    "\n",
    "plg = plg['pwr']\n",
    "plg = plg.to_numpy()\n",
    "\n",
    "#split to time windows with 50% overlap\n",
    "meter = window(sm, 10,5)\n",
    "met_cur = window(met_cur,10,5)\n",
    "plug = window(plg,10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract features\n",
    "\n",
    "\n",
    "\n",
    "Y = np.array([])\n",
    "X = np.empty((0,10))\n",
    "\n",
    "# mean,min,max,median,rms,perc25,perc75,std,energy\n",
    "for i in range(0,len(plug)):\n",
    "    Y = np.append(Y,np.mean(plug[i,:]))\n",
    "    X = np.append(X,np.array([[np.mean(meter[i,:]),np.min(meter[i,:]),np.max(meter[i,:]),\\\n",
    "            np.median(meter[i,:]),np.sqrt(np.mean(meter[i,:]**2, axis=None)),\\\n",
    "            np.percentile(meter[i,:],25),np.percentile(meter[i,:],75),np.std(meter[i,:]),\\\n",
    "                                    np.sum(meter[i,:]),np.mean(met_cur[i,:])]]),axis = 0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n_test = int(0.33*len(features))\n",
    "# trainX, testX = features[0:-n_test], features[-n_test:]\n",
    "# trainY, testY = appl[0:-n_test], appl[-n_test:]\n",
    "\n",
    "# split train and test\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.33, random_state=42,shuffle = False)\n",
    "print('trainX size:',trainX.shape)\n",
    "print('trainY size:',trainY.shape)\n",
    "acc = build_model(trainX,trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X)\n",
    "err = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    trainX, testX = X[train_index], X[test_index]\n",
    "    trainY, testY = Y[train_index],Y[test_index]\n",
    "    \n",
    "    acc = build_model(trainX,trainY, testX, testY)\n",
    "    \n",
    "    print('Accuracy of fold is:', acc)\n",
    "    err.append(acc)\n",
    "\n",
    "print('Mean accuracy of 10 folds:',np.mean(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X)\n",
    "err = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    trainX, testX = X[train_index], X[test_index]\n",
    "    trainY, testY = Y[train_index],Y[test_index]\n",
    "    \n",
    "    mdl = RandomForestRegressor(n_estimators=8,random_state=0)\n",
    "    mdl.fit(trainX, trainY)\n",
    "    pred = mdl.predict(testX)\n",
    "    \n",
    "    acc = appliance_acc(testY,pred)\n",
    "    \n",
    "    print('Accuracy of fold %d is: %f' % (i, acc))\n",
    "    err.append(acc)\n",
    "\n",
    "print('Mean accuracy of 10 folds:',np.mean(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl = RandomForestRegressor(n_estimators=32,random_state=0)\n",
    "# mdl = KNeighborsRegressor(n_neighbors=5)\n",
    "mdl.fit(trainX, trainY)\n",
    "pred = mdl.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = [17,10])\n",
    "plt.grid(True)\n",
    "plt.plot(testY)\n",
    "plt.plot(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = appliance_acc(testY,pred)\n",
    "print('Accuracy:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mape = mean_absolute_percentage_error(testY,pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
